"""
üå∏ Machine Learning
Aluna: Danielle Torres

Classifica√ß√£o do dataset Iris

Configura√ß√£o do ambiente
"""

#%% Ambiente e Imports

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline, make_pipeline

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

from sklearn.ensemble import (
    BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier,
    VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier
)

#%%
"""
Carga do Dataset

Esta c√©lula carrega o dataset Iris, um cl√°ssico em problemas de classifica√ß√£o,
a partir de um arquivo CSV hospedado no GitHub. O dataset √© lido usando a biblioteca pandas.

O conjunto de dados cont√©m informa√ß√µes sobre flores da esp√©cie Iris, com as seguintes vari√°veis:
- SepalLengthCm: comprimento da s√©pala em cent√≠metros
- SepalWidthCm: largura da s√©pala em cent√≠metros
- PetalLengthCm: comprimento da p√©tala em cent√≠metros
- PetalWidthCm: largura da p√©tala em cent√≠metros
- Species: esp√©cie da flor, que pode ser uma das tr√™s classes:
    - Iris-setosa
    - Iris-versicolor
    - Iris-virginica 
    
Essas vari√°veis s√£o atributos que ser√£o usados para treinar e avaliar modelos de aprendizado de m√°quina.
Ap√≥s o carregamento, s√£o exibidas as primeiras linhas do dataset e um resumo da estrutura dos dados.
"""

# Caminho do arquivo
dataset_path = "https://raw.githubusercontent.com/DanielleTorree/ML4Iris/main/api/MachineLearning/dataset/dataset_iris.csv"

# Leitura
dataset = pd.read_csv(dataset_path)

# Visualiza√ß√£o inicial
dataset.head()
dataset.info()

#%%
"""
Separa√ß√£o dos Dados

Nesta etapa, o conjunto de dados √© preparado para o treinamento e avalia√ß√£o do modelo.

Primeiramente, s√£o separadas as vari√°veis independentes (X) e a vari√°vel dependente (y):
- X corresponde √†s quatro caracter√≠sticas num√©ricas das flores.
- y corresponde √† esp√©cie da flor, que √© a vari√°vel alvo.

Em seguida, os dados s√£o divididos em dois subconjuntos:
- Conjunto de treino (80%)
- Conjunto de teste (20%)
A divis√£o √© realizada de forma estratificada, mantendo a propor√ß√£o das classes da vari√°vel alvo.

Tamb√©m √© definida a estrat√©gia de valida√ß√£o cruzada:
- Utiliza-se o m√©todo StratifiedKFold com 10 divis√µes (folds)
- A valida√ß√£o √© estratificada e embaralhada, garantindo representatividade das classes em cada parti√ß√£o
- A m√©trica escolhida para avalia√ß√£o √© a acur√°cia ("accuracy")
"""

# Defini√ß√µes
test_size = 0.20
seed = 7

# Separa√ß√£o entre atributos (X) e classe (y)
X = dataset.iloc[:, 0:4].values
y = dataset.iloc[:, 4].values

# Holdout com estratifica√ß√£o
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=seed, stratify=y
)

# Valida√ß√£o cruzada estratificada
num_folds = 10
scoring = "accuracy"
kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)

#%%
"""
## Modelagem - Linha Base e Ensembles

Neste bloco, s√£o definidos os modelos que ser√£o utilizados na avalia√ß√£o.

Primeiro, s√£o criados os modelos de linha base, que servem como refer√™ncia inicial de desempenho.
Esses modelos incluem:
- Regress√£o Log√≠stica (LR)
- K-Nearest Neighbors (KNN)
- √Årvore de Decis√£o (CART)
- Naive Bayes (NB)
- Suporte a Vetores de M√°quinas (SVM)

Em seguida, s√£o definidos os modelos do tipo ensemble, que combinam v√°rios algoritmos
para melhorar a precis√£o das previs√µes. Entre eles est√£o:
- Bagging
- Random Forest
- Extra Trees
- AdaBoost
- Gradient Boosting
- VotingClassifier (que combina Regress√£o Log√≠stica, √Årvore de Decis√£o e SVM)

Todos os modelos s√£o reunidos na lista 'all_models', que ser√° usada na etapa de avalia√ß√£o.
"""

np.random.seed(seed)

# Modelos base
base_models = [
    ("LR", LogisticRegression(max_iter=200)),
    ("KNN", KNeighborsClassifier()),
    ("CART", DecisionTreeClassifier()),
    ("NB", GaussianNB()),
    ("SVM", SVC())
]

# Ensembles
base_estimator = DecisionTreeClassifier()
num_trees = 100
max_features = 3

voting_models = [
    ("logistic", LogisticRegression(max_iter=200)),
    ("cart", DecisionTreeClassifier()),
    ("svm", SVC())
]

ensemble_models = [
    ("Bagging", BaggingClassifier(estimator=base_estimator, n_estimators=num_trees)),
    ("RF", RandomForestClassifier(n_estimators=num_trees, max_features=max_features)),
    ("ET", ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)),
    ("Ada", AdaBoostClassifier(n_estimators=num_trees)),
    ("GB", GradientBoostingClassifier(n_estimators=num_trees)),
    ("Voting", VotingClassifier(estimators=voting_models))
]

# Junta todos os modelos
all_models = base_models + ensemble_models

#%%
"""
## Avalia√ß√£o dos Modelos

Nesta etapa, os modelos definidos anteriormente s√£o avaliados.

Cada modelo √© testado utilizando valida√ß√£o cruzada com 10 divis√µes (StratifiedKFold),
o que permite estimar seu desempenho de forma mais confi√°vel.

Para cada modelo, s√£o calculadas as m√©dias e desvios padr√£o das acur√°cias obtidas em cada divis√£o.
Os resultados s√£o armazenados para posterior compara√ß√£o.

Por fim, √© gerado um gr√°fico de boxplot que permite visualizar, de forma clara,
o desempenho de todos os modelos com base na m√©trica de acur√°cia.
"""

results = []
names = []

for name, model in all_models:
    cv_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
    results.append(cv_scores)
    names.append(name)
    print(f"{name}: {cv_scores.mean():.4f} ({cv_scores.std():.4f})")

#%% Visualiza√ß√£o

plt.figure(figsize=(15, 8))
plt.title("Compara√ß√£o dos Modelos - Acur√°cia")
plt.boxplot(results, labels=names)
plt.ylabel("Acur√°cia")
plt.grid(True)
plt.show()

#%%
"""
## Modelagem com dados padronizados e normalizados usando Pipelines

Nesta etapa, os modelos s√£o avaliados considerando diferentes formas de pr√©-processamento dos dados.

S√£o utilizadas tr√™s vers√µes dos dados para treinamento:
- Dados originais, sem transforma√ß√£o
- Dados padronizados, aplicando StandardScaler, que transforma cada valor conforme a f√≥rmula:
 
  F√≥rmula: $z_i = \frac{x_i - \mu}{\sigma}$

  onde $\mu$ √© a m√©dia da vari√°vel e $\sigma$ √© o desvio padr√£o.

- Dados normalizados, aplicando MinMaxScaler, que escala os valores para o intervalo [0, 1] segundo a f√≥rmula:

  F√≥rmula: $x'_i = \frac{x_i - x_{min}}{x_{max} - x_{min}}$

  onde $x_{min}$ e $x_{max}$ s√£o os valores m√≠nimo e m√°ximo da vari√°vel, respectivamente.

Para facilitar o processo, s√£o criadas pipelines que combinam o pr√©-processamento com cada modelo.

Cada pipeline √© avaliada usando valida√ß√£o cruzada estratificada com 10 folds, calculando-se a acur√°cia m√©dia e o desvio padr√£o.

Os resultados s√£o apresentados em um gr√°fico de boxplot para comparar o desempenho dos modelos nas tr√™s vers√µes dos dados.
"""

standard_scaler = ("StandardScaler", StandardScaler())
minmax_scaler = ("MinMaxScaler", MinMaxScaler())

pipelines = []

# Criando pipelines para cada modelo e cada tipo de pr√©-processamento
for name, model in all_models: 
    pipelines.append((f"{name}-orig", Pipeline(steps=[(name, model)])))
    pipelines.append((f"{name}-std", Pipeline(steps=[standard_scaler, (name, model)])))
    pipelines.append((f"{name}-minmax", Pipeline(steps=[minmax_scaler, (name, model)])))

results = [] 
names = []

for name, pipeline in pipelines:
    cv_results = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    print(f"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})")

plt.figure(figsize=(25, 6))
plt.title("Compara√ß√£o de Modelos - Dataset Original, Padronizado e Normalizado")
plt.boxplot(results, labels=names)
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

#%%
"""
Otimiza√ß√£o de hiperpar√¢metros com Grid Search

Nesta etapa, √© realizada a otimiza√ß√£o dos hiperpar√¢metros de alguns modelos selecionados.

Define-se um conjunto de par√¢metros (param_grid) para os modelos:
- Regress√£o Log√≠stica (LR)
- K-Nearest Neighbors (KNN)
- Random Forest (RF)

Para cada modelo e seu respectivo pipeline, √© aplicado o Grid Search com valida√ß√£o cruzada de 5 folds,
buscando a combina√ß√£o de par√¢metros que maximiza a acur√°cia.

Ao final, √© exibida a melhor pontua√ß√£o obtida e os par√¢metros correspondentes para cada modelo otimizado.
"""
param_grids = {
    "LR": {
        "LR__C": [0.5, 1, 2],  # Faixa em torno do melhor valor encontrado (1)
        "LR__solver": ["saga"],  # Melhor solver encontrado
    },
    "KNN": {
        "KNN__n_neighbors": [9, 11, 13],  # Em torno do melhor (11)
        "KNN__metric": ["euclidean"],     # Melhor m√©trica encontrada
    },
    "RF": {
        "RF__n_estimators": [5, 10, 20],            # Faixa menor, centrada no melhor (10)
        "RF__max_features": ["sqrt"],               # Melhor resultado
        "RF__max_depth": [None, 10],                # Melhor resultado: None
        "RF__min_samples_split": [2, 5],            # Ambos deram bons resultados
        "RF__min_samples_leaf": [1, 2],             # Ambos foram usados nos melhores casos
    }
}

# Para modelos onde aplicaremos Grid Search (exemplo: LR, KNN, RF)
grid_models = ["LR", "KNN", "RF"]

kfold_gs = 5

for name, pipeline in pipelines:
    model_key = name.split("-")[0]
    if model_key in grid_models:
        param_grid = param_grids[model_key]
        grid = GridSearchCV(pipeline, param_grid=param_grid, scoring=scoring, cv=kfold_gs, n_jobs=-1)
        grid.fit(X_train, y_train)
        print(f"Modelo: {name} - Melhor: {grid.best_score_:.4f} usando {grid.best_params_}")

"""
# Modelo: LR-orig - Melhor: 0.9833 usando {'LR__C': 0.5, 'LR__solver': 'saga'}
# Modelo: LR-std - Melhor: 0.9500 usando {'LR__C': 0.5, 'LR__solver': 'saga'}
# Modelo: LR-minmax - Melhor: 0.9417 usando {'LR__C': 2, 'LR__solver': 'saga'}
# Modelo: KNN-orig - Melhor: 0.9750 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 11}
# Modelo: KNN-std - Melhor: 0.9583 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 9}
# Modelo: KNN-minmax - Melhor: 0.9500 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 9}
# Modelo: RF-orig - Melhor: 0.9500 usando {'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__min_samples_leaf': 2, 'RF__min_samples_split': 2, 'RF__n_estimators': 5}
# Modelo: RF-std - Melhor: 0.9583 usando {'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__min_samples_leaf': 1, 'RF__min_samples_split': 5, 'RF__n_estimators': 5}
# Modelo: RF-minmax - Melhor: 0.9667 usando {'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__min_samples_leaf': 2, 'RF__min_samples_split': 2, 'RF__n_estimators': 20}
"""

#%%
"""
Treinamento final e avalia√ß√£o no conjunto teste

Nesta etapa, o modelo final escolhido, uma Random Forest com par√¢metros espec√≠ficos,
√© treinado usando o conjunto de dados de treinamento.

O pipeline inclui a normaliza√ß√£o dos dados com MinMaxScaler antes do treinamento.

Ap√≥s o treinamento, o modelo √© testado no conjunto de teste separado anteriormente,
e a acur√°cia obtida √© exibida para avaliar o desempenho do modelo na generaliza√ß√£o.

"""
from sklearn.pipeline import make_pipeline

np.random.seed(seed)

final_model = RandomForestClassifier(
    n_estimators=50,
    max_features="sqrt",
    min_samples_split=2,
    max_depth=10,
    min_samples_leaf=1,
)

pipeline_final = make_pipeline(MinMaxScaler(), final_model)
pipeline_final.fit(X_train, y_train)

y_pred = pipeline_final.predict(X_test)
print(f"Acur√°cia no conjunto teste: {accuracy_score(y_test, y_pred):.4f}")

#%%
"""
Salvando modelo e scaler

Nesta etapa, s√£o criadas pastas para armazenar os arquivos gerados durante o processo,
garantindo que os diret√≥rios existam.

Em seguida, s√£o salvos em disco:
- O modelo final treinado (Random Forest) no arquivo "rf_iris_classifier.pkl"
- O objeto do scaler utilizado (MinMaxScaler) no arquivo "minmax_scaler_iris.pkl"
- A pipeline completa, que inclui o pr√©-processamento e o modelo, no arquivo "rf_iris_pipeline.pkl"

Tamb√©m s√£o salvos em CSV os dados de teste (X_test e y_test), para poss√≠vel uso futuro ou valida√ß√£o externa.
"""

import os

os.makedirs("api/MachineLearning/models", exist_ok=True)
os.makedirs("api/MachineLearning/scalers", exist_ok=True)
os.makedirs("api/MachineLearning/pipelines", exist_ok=True)
os.makedirs("api/MachineLearning/data", exist_ok=True)

with open("api/MachineLearning/models/rf_iris_classifier.pkl", "wb") as f:
    pickle.dump(final_model, f)

with open("api/MachineLearning/scalers/minmax_scaler_iris.pkl", "wb") as f:
    pickle.dump(pipeline_final.named_steps["minmaxscaler"], f)

with open("api/MachineLearning/pipelines/rf_iris_pipeline.pkl", "wb") as f:
    pickle.dump(pipeline_final, f)

pd.DataFrame(X_test, columns=dataset.columns[:-1]).to_csv("api/MachineLearning/data/X_test_iris.csv", index=False)
pd.DataFrame(y_test, columns=[dataset.columns[-1]]).to_csv("api/MachineLearning/data/y_test_iris.csv", index=False)

#%% 
"""
## Simula√ß√£o de predi√ß√£o em dados novos

Nesta etapa, s√£o criados novos dados com as mesmas caracter√≠sticas do dataset original.

Os dados s√£o convertidos para o formato num√©rico e passam pelo mesmo processo de normaliza√ß√£o
utilizado no treinamento, garantindo que as escalas sejam compat√≠veis.

Em seguida, o modelo final treinado realiza as previs√µes da esp√©cie da flor para esses novos exemplos.

Por fim, as previs√µes s√£o exibidas no console.
"""

new_data = pd.DataFrame({
    "SepalLengthCm": [5.1, 6.2, 5.9, 4.7],
    "SepalWidthCm": [3.5, 2.8, 3.0, 3.2],
    "PetalLengthCm": [1.4, 4.8, 4.2, 1.3],
    "PetalWidthCm": [0.2, 1.8, 1.3, 0.2]
})

X_new = new_data.values.astype(float)
X_new_scaled = pipeline_final.named_steps["minmaxscaler"].transform(X_new)
predictions = final_model.predict(X_new_scaled)
print("Previs√µes para novos dados:", predictions)